{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The goal of a language model is to estimate the word sequence probability  \n",
    "$ P(x_1,x_2,...,x_T) $\n",
    "The predictor type llm draws one token at a time: $ x_t ~ P(x_t | x_{t-1},...,x_1) $  "
   ],
   "id": "387b0adaf01d256a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-14T17:32:34.353643Z",
     "start_time": "2024-05-14T17:32:34.341463Z"
    }
   },
   "source": [
    "import torch\n",
    "from d2l import torch as d2l"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Modeling the process  \n",
    "$ P(x_1, x_2, ..., x_T) = \\prod_{t=1}^T P(x_t | x_1, ..., x_{t-1}) $\n",
    "\n",
    "yet to simplify we use Markov models.  \n",
    "The higher the order the more past we have to see the predict the future\n",
    "$ P(x_{t+1} | x_t,...,x_1) = P(x_{t+1} | x_t) "
   ],
   "id": "20fa6d194179fb7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For metric likelihood is bad because it is very influenced from the length of each word.  \n",
    "That why we use cross entropy or **perplexity** which is the exp(cross-entropy)"
   ],
   "id": "7eaf799ad3361143"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Training: \n",
    "* The dataset Sequence has length T \n",
    "* For randomness in every epoch discard d tokens from the sequence\n",
    "* We split it in subsequences(batches) of size n\n",
    "\n",
    "**The goal**\n",
    "For language modeling, the goal is to predict the next token based on the tokens we have seen so far; hence the targets (labels) are the original sequence, shifted by one token. The target sequence for any input sequence $x_t$ is $x_{t+1}$ with length $n$."
   ],
   "id": "25f2b46618d9a321"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T17:50:09.056729Z",
     "start_time": "2024-05-14T17:50:09.047349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@d2l.add_to_class(d2l.TimeMachine)  #@save\n",
    "def __init__(self, batch_size, num_steps, num_train=10000, num_val=5000):\n",
    "    super(d2l.TimeMachine, self).__init__()\n",
    "    self.save_hyperparameters()\n",
    "    corpus, self.vocab = self.build(self._download())\n",
    "    array = torch.tensor([corpus[i:i+num_steps+1]\n",
    "                        for i in range(len(corpus)-num_steps)])\n",
    "    self.X, self.Y = array[:,:-1], array[:,1:]"
   ],
   "id": "498610f6db104940",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T17:50:31.113015Z",
     "start_time": "2024-05-14T17:50:31.094932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@d2l.add_to_class(d2l.TimeMachine)  #@save\n",
    "def get_dataloader(self, train):\n",
    "    idx = slice(0, self.num_train) if train else slice(\n",
    "        self.num_train, self.num_train + self.num_val)\n",
    "    return self.get_tensorloader([self.X, self.Y], train, idx)"
   ],
   "id": "116e3f150eee9026",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T17:50:41.279553Z",
     "start_time": "2024-05-14T17:50:39.780982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = d2l.TimeMachine(batch_size=2, num_steps=10)\n",
    "for X, Y in data.train_dataloader():\n",
    "    print('X:', X, '\\nY:', Y)\n",
    "    break\n"
   ],
   "id": "3682f4b35b1d5718",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[ 6,  0,  8,  6, 19, 14,  0, 16,  7,  0],\n",
      "        [ 0, 17,  6, 19, 20, 16, 15,  0, 24, 10]]) \n",
      "Y: tensor([[ 0,  8,  6, 19, 14,  0, 16,  7,  0, 14],\n",
      "        [17,  6, 19, 20, 16, 15,  0, 24, 10, 21]])\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
