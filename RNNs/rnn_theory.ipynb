{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "RNN generalizes the markov and n-gram predictions from n-steps back, all the way back in the sequence by adding a hidden state $h_t$, where: $$P(x_t | x_{t-1}, \\ldots, x_1) \\approx P(x_t | h_{t-1})$$,$$h_t = f(x_t, h_{t-1})____(1)$$",
   "id": "e530ac01f813f480"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-14T19:18:15.073975Z",
     "start_time": "2024-05-14T19:18:07.009307Z"
    }
   },
   "source": [
    "import torch \n",
    "from d2l import torch as d2l"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RNN theory\n",
    "* In simple NN:$X$ is not time dependent: $X \\in \\mathbb{R}^{n \\times d}$,  \n",
    "    So the output of a hidden layer is: $H = \\phi(XW_{xh} + b_h)$\n",
    "* In RNN we have the same thing just now with time: $X_t \\in \\mathbb{R}^{n \\times d}$\n",
    "    Here the from (1) we can see that wew need $H_{t-1}$ and thus we add $W_{hh}$: $$H_t = \\phi(X_t W_{xh} + H_{t-1}W_{hh} + b_h)$$  \n",
    "  The previous time $H$ becomes the hidden state since now it encapsulates the past.\n",
    "* The output is the classic output of NN: $O_t = H_tW_{hq} + b_q$"
   ],
   "id": "ca8636b5e9e90884"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Concatenation instead of Multiplication** (A more sophisticated approach)",
   "id": "50badf385f5b2d81"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![imgs/rnn_data_flow.png](imgs/rnn_data_flow.png)",
   "id": "6455c217eb9d5bfb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T19:48:43.902098Z",
     "start_time": "2024-05-14T19:48:43.887631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, W_xh = torch.randn(3, 1), torch.randn(1, 4)\n",
    "H, W_hh = torch.randn(3, 4), torch.randn(4, 4)\n",
    "add_mul_result = torch.matmul(X, W_xh) + torch.matmul(H, W_hh)\n",
    "cat_mul_result = torch.matmul(torch.cat((X, H), 1), torch.cat((W_xh, W_hh), 0))\n",
    "print(add_mul_result)\n",
    "print(cat_mul_result)"
   ],
   "id": "f4101cda05df0631",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1203, -0.8179,  0.8744,  0.1771],\n",
      "        [ 2.2148, -0.4934,  2.7883,  1.2505],\n",
      "        [ 2.7532, -3.6170,  3.5816,  0.0531]])\n",
      "tensor([[-2.1203, -0.8179,  0.8744,  0.1771],\n",
      "        [ 2.2148, -0.4934,  2.7883,  1.2505],\n",
      "        [ 2.7532, -3.6170,  3.5816,  0.0531]])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T19:48:09.912476Z",
     "start_time": "2024-05-14T19:48:09.906500Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3e0ae6b2377aa1c4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d4ac64a956c0f721"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
